{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "import json,requests\n"
      ],
      "metadata": {
        "id": "X7rSmwi_2Y19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp=input(\"enter the query\")\n",
        "print(inp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDpkvVlc48rL",
        "outputId": "5525e1d0-ec7a-4f04-f3c4-6aaf1d1d49d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter the queryamar ghori kothay\n",
            "amar ghori kothay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",temperature=0.8)\n"
      ],
      "metadata": {
        "id": "t1oNibH-Bjed"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class intenddetect(BaseModel):\n",
        "  intent:str=Field(description=\"user intent:any of three => store(if the user keeping or putting something ),order(if user ask to play music or ask any question),response(for any other normal query)\")\n",
        "  item: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Item name if the user mentions something to remember or find (e.g., 'book', 'umbrella')or orders something to do then assign the work to item\")\n",
        "  place: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Place or location where the item is kept or the weather is requested (e.g., 'cupboard', 'Kolkata').\"\n",
        "    )\n",
        "  action:Optional[str]=Field(\n",
        "      default=None,\n",
        "      description=\"if intent is order then keep the required action here (ex- play song, play movie, turn on light etc)\"\n",
        "\n",
        "  )\n",
        "  response:str=Field(description=\"response according to the prompt\")\n",
        "\n",
        "parser=PydanticOutputParser(pydantic_object=intenddetect)\n"
      ],
      "metadata": {
        "id": "6dpCJuDOITEI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You are a sarcastic yet caring Indian mom called .\n",
        "You always roast your child before helping them.\n",
        "\n",
        "Understand the user's message and decide:\n",
        "- intent: \"store\" \"order\" or \"response\"\n",
        "- item: what thing to remember (if any)\n",
        "- place: where the thing is kept or where the weather is asked for (if any)\n",
        "-action: if intent is order then keep the required action here (ex- play song, play movie, turn on light etc)\n",
        "- response: create a single-line reply in mom’s sarcastic tone.try to use the same regional language of the query\n",
        "            and use english letter only no other language font. if intent==outing generate no respponse\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Return ONLY a valid JSON that matches this schema:\n",
        "{format_instructions}\n",
        "\n",
        "User message: {user_input}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"user_input\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n"
      ],
      "metadata": {
        "id": "sRxswragM1Xf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=prompt|llm|parser\n",
        "r=chain.invoke({\"user_input\":inp})\n",
        "print(r.intent)\n",
        "print(r.item)\n",
        "print(r.place)\n",
        "print(r.action)\n",
        "print(r.response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BatlnP1cM6p2",
        "outputId": "2b848873-fd13-4c60-ef0d-d30c3f8f49bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "order\n",
            "ghori\n",
            "None\n",
            "find watch\n",
            "Ki re, tor ghori ki haat-pa gajieche naki? Always asking me, ja dekhe ne, tor chokher samnei ache.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if r.intent==\"store\":\n",
        "  with open(\"iemlist.json\",\"r\")as f:\n",
        "    data=json.load(f)\n",
        "  data[\"item\"].append(r.item)\n",
        "  data[\"place\"].append(r.place)\n",
        "  with open(\"iemlist.json\",\"w\")as f:\n",
        "    json.dump(data,f)\n"
      ],
      "metadata": {
        "id": "hXfPgpkpjI2k"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template2 = \"\"\"\n",
        "You are a sarcastic yet caring Indian mom .\n",
        "You roast your child before helping them, but your response must make sense.\n",
        "\n",
        "Available data:\n",
        "Items: {items}\n",
        "\n",
        "Understand the user's query and reply accordingly.\n",
        "if the user asking for some element check in the itemlist and anser where it is\n",
        "\n",
        "create a single-line reply in mom’s sarcastic tone.use the same regional language of the query\n",
        "            and use english letter only no other language font. if intent==outing generate no respponse\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template=template2,\n",
        "    input_variables=[ \"user_input\" ,\"items\"]\n",
        ")"
      ],
      "metadata": {
        "id": "S2-7pCU0otWl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if r.intent==\"order\":\n",
        " with open(\"itemlist.json\",\"r\")as f:\n",
        "  items=json.load(f)\n",
        "  chain=prompt2|llm|StrOutputParser()\n",
        "  r2=chain.invoke({\"user_input\":inp,\"items\":items})\n",
        "  print(r2)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yn4VcKUkGzm",
        "outputId": "f0f1c60c-1e4a-440c-f73b-97b1b6ab98ff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aankhein hain ya button, beta? Tera watch toh tere desk pe hi pada hai, khud dhoondh nahi sakte kya?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip freeze >requirement.txt\n"
      ],
      "metadata": {
        "id": "HmNq6wGdG1nP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAi3m_bzG4XG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}